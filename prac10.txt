%pip install nltk
import nltk
nltk.download('punkt', download_dir='./nltk_data')


file_path = 'text.txt'

with open(file_path, 'r', encoding='utf-8') as file:
    text = file.read()
text = text.lower() 
print(text) 


import string 
print(string.punctuation)



text_p = "".join([char for char in text if char not in string.punctuation])
print(text_p)


from nltk import word_tokenize, sent_tokenize
nltk.download('punkt_tab')
words = word_tokenize(text_p) 
words1 = sent_tokenize(text_p) 
print(words) 
print(words1)




nltk.download('stopwords') 
from nltk.corpus import stopwords 
stop_words = stopwords.words('english') 
print(stop_words)



filtered_words = [word for word in words if word not in stop_words] 
print(filtered_words)


from nltk.stem.porter import PorterStemmer 
porter = PorterStemmer() 
stemmed = [porter.stem(word) for word in filtered_words] 
print(stemmed)


import nltk 
nltk.download('averaged_perceptron_tagger_eng') 

from nltk import pos_tag 
pos = pos_tag(filtered_words)
print(pos)


%pip install scikit-learn
from sklearn.feature_extraction.text import TfidfVectorizer
corpus = [text]
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)




terms = tfidf_vectorizer.get_feature_names_out()
print("TF-IDF Terms:", terms)



tfidf_values = tfidf_matrix.toarray()
print("TF-IDF Values:", tfidf_values)
